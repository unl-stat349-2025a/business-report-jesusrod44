---
title: "Methods"
editor: visual
---

# Methods

## Load Neccessary Libraries

Throughout the statistical , many R packages were used. There were three packages used to read in data, these being the readr and readxl packages which were used to read in common data formats such as .csv and .xlsx, while the sf package was used primarily for spatial data such as .shp and .kml files. The sf package was used to perform some data wrangling on spatial data as well. Other packages for data wrangling, cleaning, and manipulation were the dplyr, tidyverse, and stringr. The ggplot2 package was used to help make well designed charts and maps with accompanying titles, captions, and tags. With the use of ggplot(), the maps and mapdata packages were loaded in order to create maps of the United States, the West Coast, the Gulf of Mexico and East Coast, as well as Hawaii. Lastly, the knitr and patchwork packages were utilized to create better looking tables and charts in the quarto document. 

```{r, echo=FALSE, output=FALSE, message = F, warning = F}
#| label: Load neccessary libraries 
library(ggplot2)
library(readr)
library(readxl)
library(sf)
library(dplyr)
library(tidyverse)
library(stringr)
library(mapdata)
library(maps)
library(knitr)
library(patchwork)
```

## Shark Data

Four shark datasets were used in this business report. Three come from trusted government agencies and report a survey of sharks tagged in the Gulf of Mexico, Florida, and Hawaii. The fourth one differs from the rest, being that it is data recorded on shark incidents in California.

### Cleaning Shark Data

Not much data wrangling was needed to prepare for shark distribution plotting. However, in California's shark incident dataset, empty longitude and latitude were removed. 

These are the following sharks included in each dataset. 

```{r, echo=FALSE, warning=FALSE, output = FALSE, message = F}
#| label: Loading in Shark Data
shark_survey_dataframe <- read_excel("Datasets/Shark Datasets/NMFS BLL data Susan V.xlsx")
shark_dataframe <- read_csv("Datasets/Shark Datasets/Biological _Data_SBK.csv")
shark_incidents_california <- read_excel(
  "Datasets/Shark Datasets/SharkIncidents_1950_2022_220302.xlsx")
shark_hawaii <- st_read("Datasets/Shark Datasets/PACIOOS_WMS_ONLY-hi_pacioos_all_shark_tiger.kml")

```

```{r, echo = FALSE, output = FALSE, message = F, warning = F}
#| label: Shark Dataset Cleaning 
shark_incidents_california <- shark_incidents_california %>% 
  filter(!is.na(Latitude))
shark_incidents_california$Longitude <- as.numeric(shark_incidents_california$Longitude)
str(shark_incidents_california)
```

```{r, echo= FALSE, output = F, warning = F, message = F }
#| label: Names of Sharks in our Datasets

unique(shark_incidents_california$Species)

# Create the lookup table (without Blue*)
shark_table_california <- tribble(
  ~ScientificName, ~CommonName, ~MaxWeight,
  "PRIONACE_GLAUCA", "Blue", 400,
  "SPHYRNA_MOKARRAN", "Hammerhead", 992,
  "ORCINUS_ORCA", "Killer Whale", 8800,
  "TRIAKIS_SEMIFASCIATA", "Leopard", 70,
  "LAMNA_DITROPIS", "Salmon", 992,
  "NOTORYNCHUS_CEPEDIANUS", "Sevengill", 1100,
  "ALOPIAS_VULPINUS", "Thresher", 1102,
  "UNKNOWN", "Unknown", NA,
  "CARCHARODON_CARCHARIAS", "White", 5000
)
```

```{r, echo = F, message = F, warning = F}
# Display the table nicely
kable(shark_table_california,
      col.names = c("Scientific Name", "Common Name", "Max Weight (lbs)"),
      align = c("l", "l", "r"),
      caption = "Table 3: Names and Estimated Weights of Sharks in California Dataset")

# create the lookup table 
shark_table_gulf_atlantic <- tribble(
  ~ScientificName, ~CommonName, ~MaxWeight,
" ALOPIAS_VULPINUS", "Common Thresher        ",           1102.3, 
" CARCHARHINUS_ACRONOTUS", "Blacknose              ",             39.7 ,
" CARCHARHINUS_ALTIMUS", "Bignose                ",            370.4 ,
" CARCHARHINUS_BREVIPINNA", "Spinner                ",            198.4 ,
" CARCHARHINUS_FALCIFORMIS", "Silky                  ",            762.8, 
" CARCHARHINUS_ISODON", "Finetooth              ",             30.0 ,
" CARCHARHINUS_LEUCAS", "Bull                   ",            507.1 ,
" CARCHARHINUS_LIMBATUS", "Blacktip               ",            269.0, 
" CARCHARHINUS_OBSCURUS", "Dusky                  ",            762.8 ,
" CARCHARHINUS_PEREZII", "Caribbean Reef         ",            154.3 ,
" CARCHARHINUS_PLUMBEUS", "Sandbar                ",            257.9 ,
" CARCHARHINUS_POROSUS", "Smalltail              ",             19.8 ,
" CARCHARHINUS_SIGNATUS", "Night                  ",             39.7 ,
" CENTROPHORUS_GRANULOSUS", "Gulper                 ",             24.3, 
" CENTROPHORUS_UYATO", "Little Gulper          ",              6.6 ,
" CIRRHIGALEUS_ASPER", "Roughskin Spurdog      ",             33.1 ,
" GALEOCERDO_CUVIER", "Tiger                  ",           1984.2 ,
" GINGLYMOSTOMA_CIRRATUM", "Nurse                  ",            242.5, 
" HEPTRANCHIAS_PERLO", "Sharpnose Sevengill    ",             44.1 ,
" HEXANCHUS_GRISEUS", "Bluntnose Sixgill      ",           2425.1 ,
" HEXANCHUS_NAKAMURAI", "Bigeye Sixgill         ",            352.7, 
" MUSTELUS_CANIS", "Dusky Smooth-hound     ",             26.5 ,
" MUSTELUS_NORRISI", "Narrowfin Smooth-hound ",             15.4, 
" MUSTELUS_SINUSMEXICANUS", "Gulf Smooth-hound      ",             22.0, 
" NEGAPRION_BREVIROSTRIS", "Lemon                  ",            403.4 ,
" RHIZOPRIONODON_TERRAENOVAE", "Atlantic Sharpnose     ",              9.9, 
" SCYLIORHINUS_RETIFER", "Chain Catshark         ",              3.3 ,
" SPHYRNA_LEWINI", "Scalloped Hammerhead   ",            334.1 ,
" SPHYRNA_MOKARRAN", "Great Hammerhead       ",            992.1, 
" SPHYRNA_TIBURO", "Bonnethead             ",             22.0 ,
" SQUALUS_ACANTHIAS", "Spiny Dogfish          ",             19.8, 
" SQUALUS_CUBENSIS", "Cuban Dogfish          ",             15.4 ,
" SQUALUS_MITSUKURII", "Shortspine Spurdog     ",             17.6 ,
" SQUATINA_DUMERIL", "Atlantic Angel Shark   ",             77.2
)
kable(shark_table_gulf_atlantic,
      col.names = c("Scientific Name", "Common Name", "Max Weight (lbs)"),
      align = c("l", "l", "r"),
      caption = "Table 4: Names and Estimated Weights of Sharks in Gulf of Mexico and Altantic Dataset")

shark_table_hawaii <- tribble(
  ~ScientificName, ~CommonName, ~MaxWeight, 
  " GALEOCERDO_CUVIER", "Tiger                  ",           1984.2 
)

kable(shark_table_hawaii, 
      col.names = c('Scientic Name', "Common Name", "Max Weight (lbs)"),
      align = c("l", "l", "r"), 
      caption = "Table 5: Names and Estimated Weights of Sharks in Hawaii Shark Dataset")

```

## Tornado Data

Five datasets from the past 5 years as of 2025, each containing information for a different year, were analyzed in this report. All datasets were taken from the same source, National Oceanic and Atmospheric Association (NOAA).

The reasoning behind only including data from the past five years is climate change and recent weather activity. Modern tornado data is more valuable to be analyzed in this report due to modern weather trends. So, even with NOAA offering data recorded starting from the year 1950, only current data was implemented to be analyzed. 

```{r, echo=FALSE, output=FALSE, message = F, warning = F}
#| label: Load Tornado Data from NOAA
tornado_2020_2024_dataframe <- bind_rows(
  read_csv("Datasets/Tornado_Datasets/StormEvents_details-ftp_v1.0_d2024_c20250216.csv"),
  read_csv("Datasets/Tornado_Datasets/StormEvents_details-ftp_v1.0_d2023_c20250216.csv"), 
  read_csv("Datasets/Tornado_Datasets/StormEvents_details-ftp_v1.0_d2022_c20241121.csv"), 
  read_csv("Datasets/Tornado_Datasets/StormEvents_details-ftp_v1.0_d2021_c20240716.csv"), 
  read_csv("Datasets/Tornado_Datasets/StormEvents_details-ftp_v1.0_d2020_c20240620.csv"))
```

### Cleaning Tornado Data

The storm events included in this dataset ranged from avalanches to thunderstorms. Due to interest only being in the events: Tornadoes and Waterspouts, all other unneccessary events were filtered out and removed from the data. These two events were then categorized in their own dataset. 

In the waterspout dataset, the latter, less powerful fair weather waterspouts were removed in order to evaluate tornadic waterspouts. For this to be done, in the data's 'Event Narrative' columns, where they include a brief summary on the event, only cases where the string *"tornad"* were selected, as this string would keep observations that discussed waterspouts that either: Were tornadic waterspouts or transformed into tornadoes. 

For the filtered tornado dataset, observations where the EF Score of a tornado was "EFU" meaning unknown were removed in order to keep tornadoes with a properly rated EF Scale. 

In both filtereed datasets, rows wth 'NA' values in thier beginning and ending latitude and longitude values were excluded. 

```{r, echo=FALSE, output=FALSE, message = F, warning = F}
#| label: Cleaning Tornado Data
# Remove rows containing NA values and Keep the two events we are interested in
tornado_2020_2024_clean_dataframe <- tornado_2020_2024_dataframe %>% 
  drop_na(BEGIN_LAT, BEGIN_LON, END_LON, END_LAT) %>% 
  filter(str_detect(EVENT_TYPE, "Tornado") | str_detect(EVENT_TYPE, "Waterspout"))
                                        
# Filter for Waterspouts
waterspout_dataframe <- tornado_2020_2024_clean_dataframe %>%
  filter(EVENT_TYPE == 'Waterspout')

# Filter for tornadic waterspouts
tornadic_waterspout_dataframe <- waterspout_dataframe %>%
  filter(str_detect(EVENT_NARRATIVE, 'tornad') | str_detect(EVENT_NARRATIVE, 'Tornad'))

# tornadoes only 
tornado_only_2020_2024_clean_dataframe <- tornado_2020_2024_dataframe %>% 
  drop_na(BEGIN_LAT, BEGIN_LON, END_LON, END_LAT) %>% 
  filter(EVENT_TYPE == 'Tornado') %>% 
  filter(TOR_F_SCALE %in% c('EF1', 'EF2', 'EF3', 'EF4', 'EF5'))
```

## Coastal Data 

Coastal data for the United States was taken from the United States Geological Survey (USGS). This data set included data plotting the borders of U.S. coasts as well as U.S. territories, the latter was rejected for this report. 

### Preparing Coastal Data for Plotting Maps

In order to overlay what parts our coastal data define the coasts in the United States, a plot consisting of both coordinate and spatial data was made.

The way to plot the coasts differed due to the data being spatial. The sf package was used to highlight (what the dataset considered) the coasts with a red outline. The coordinates were changed to make maps of the following regions: United States, The Southeast and Gulf of Mexico, The West Coast, and Hawaii.

This processed gave us the maps to be plotting shark and tornadoes with. 

```{r, echo=FALSE, output=FALSE, message = F, warning = F}
#| label: Loading In Coastal Data
# coastal data
coastal_dataframe <- 
  read_sf("Datasets/Coastal Datasets/CZMP_counties_2009/CZMP_counties_2009.shp")

```

```{r, echo=FALSE, output=FALSE, message = F, warning = F}
#| label: Getting the map to work
# Let's add a world map to see where those other coasts are from
world <- map_data('world')
states <- map_data('state')

ggplot(world) +
  geom_polygon(data = world, aes(x = long, y = lat, group = group), 
               fill = "gray", color = "black") +
  geom_polygon(data = states, aes(x = long, y = lat, group = group), 
               fill = "gray", color = "black") +
  theme_bw() +  
  geom_sf(aes(geometry = geometry), color = 'red', data = coastal_dataframe)
```

```{r, echo=FALSE, output=FALSE, message = F, warning = F}
#| label: Getting a US Map
# Let's look at the US individually first, then Hawaii, then Alaska

ggplot(world) +
  geom_polygon(data = world, aes(x = long, y = lat, group = group), 
               fill = "gray", color = "black") +
  geom_polygon(data = states, aes(x = long, y = lat, group = group), 
               fill = "gray", color = "black") +
  theme_bw() +  
  geom_sf(aes(geometry = geometry), color = 'red', data = coastal_dataframe) +
  coord_sf(xlim = c(-130, -60), ylim = c(20, 55))

```

## Comparing Waterspouts to Tornadoes

Tornadoes and waterspouts are classified as two different events. Both fit one of the requirements for a sharknado: The event must form over *or* near shark-inhabited waters. However, there is no simple, concrete way to measure the power scale of waterspouts. Therefore, an oversimplified way to check how much damage they are capable of is to look at the average cost of property each event has caused in our sample. 

The following data wrangling was needed in order to get a clean chart comparing the averages. The data's property damage column was formatted as 100K or 1M, meaning $100,000 and $1,000,000. To combat this, rows with the letters K or M in the "DAMAGE_PROPERTY" column were multiplied by 1000 and 10000000. This prepared the property damage to be averaged out and listed in a chart using ggplot() from the ggplot2 packge. 

## Plotting Waterspouts

When plotting waterspouts, only the tornadic waterspouts were considered, as these are more related to tornadoes and cause a much bigger disruption than fair weather waterspouts. In ggplot(), geom_segment() was used to plot the beginning and end points of waterspouts, to see if they'd move inland. Although some do, most do not move a noticeable distance away from there beginning coordinates, and if they do, they do not make landfall.

## Plotting Tornadoes

When plotting tornadoes, it is a very similar process to plotting waterspouts. In this situation, we only want tornadoes as our EVENT_TYPE. In the beginning, using geom_segment() was considered when plotting tornadoes, however, this caused the map to become more bloated than it already is, so it has been commented out in the code.

## Bootstrap Sampling Assuming Perfect Conditions

Theoretically, assume the two most powerful tornadoes, EF4 and EF5, will become sharknados, given that they are coastal tornadoes, in other words: they form inside in the coastal data's spatial perimeter. 

### Joining Spatial Coastal Data and Regular Lat-Long Tornado Data

In this report, a 'coastal tornado' is defined as a tornado that falls inside the coordinates of the multipolygon coastal spatial data plotted. Some implications such as tornado points that fall on the borders will arise from this however. 

The tornadoes coordinate data points were joined with the coastal spatial data polygons. The tornado points were transformed into spatial data via st_transform() from the 'sf' package. Then with the st_join() from the same package, we can finally filter all the points inside the coastal regions like we want. Here, the observed proportion of EF4 and EF5 tornadoes on the coasts was also found and it will be shown in the results.

### Bootstrap Histogram

A histogram is made to show the distribution of the bootstrapped proportions, with a red dashed line showing the mean of these samples. Assuming an alpha level of 0.05. A long run proportion greater than 0.05 will be needed to state that, *assuming perfect conditions*, a sharknado will form. 


