[
  {
    "objectID": "draft-data-doc.html",
    "href": "draft-data-doc.html",
    "title": "Appendix A — Draft: Data Documentation",
    "section": "",
    "text": "Here is some databases I’ve found that may be able to help answer this question\nhttps://www.fisheries.noaa.gov/inport/item/46426\n\n######### shark data\nlibrary(readr)\nBiological_Data_SBK &lt;- read_csv(\"Datasets/Shark Datasets/Biological _Data_SBK.csv\")\n\nNew names:\nRows: 99 Columns: 26\n── Column specification\n──────────────────────────────────────────────────────── Delimiter: \",\" chr\n(14): Shark_Number...1, Gear_code, Gear_Description, Location_Code, Loca... dbl\n(12): Month, Day, Year, Latitude, Longitude, Fork_length, Stomach Weight...\nℹ Use `spec()` to retrieve the full column specification for this data. ℹ\nSpecify the column types or set `show_col_types = FALSE` to quiet this message.\n• `Shark_Number` -&gt; `Shark_Number...1`\n• `Shark_Number` -&gt; `Shark_Number...16`\n\n\nWho collected the data: The first dataset is from the Southeast Fisheries Science Center which is a part of NOAA Fisheries and National Ocean Services database.\nWhy was the data collected: The data was collected to investigate the foraging ecology of early life stages of blacktip sharks in Florida, to determine levels of resource overlap.\nWhat is the data about: The data is about analyzing the biological information and diet information of blacktip sharks in Florida to examine foraging ecology, bioenergetics, and trophic level.\nWhen was the data collected: The data was collected from 2008 to 2010\nWhere was the data collected: The data was collected at Crooked Island Sound and Gulf of Mexico side of St. Vincent Island, Florida\nHow was the data generated: The data was generated by using either a gillnet or bottom longline and bait to sample sharks and record their biological informaiton and diet information\nStructure: .csv file\nFormatting descisions: Day, Month, and Year each have their own separate columns\nData Validation / Quality control: This is from a government site so it will hopefully be of good quality some missing values\nLicense: There is no Data Access Policy or Use Constraints listed\nhttps://catalog.data.gov/dataset/shark-and-red-snapper-bottom-longline-survey?utm_source=chatgpt.com\n\n# NOAA \n# given from Dr. VanderPlas \nlibrary(readxl)\n\nWarning: package 'readxl' was built under R version 4.4.3\n\nNMFS_BLL_data_Susan_V &lt;- read_excel(\"Datasets/Shark Datasets/NMFS BLL data Susan V.xlsx\")\n\nWho collected the Data: The Southeast Fisheries Science Center which is a part of NOAA\nWhy was the data collected: Provide standardized, fisheries-independent information on the abundance and distribution of shark, snapper, and grouper species\nWhat the data is about: It includes details such as species identification, measurements, weights, and life history data related to age, growth, and reproduction\nWhen the data was collected: The data was collected from 2010 to 2024\nWhere the data was collected: The data was collected on survey sites around the coasts of the Southeast of the United States and in the Gulf of Mexico\nHow was the data generated: The data was generated by using a bottom longline to collect sharks. Sampling occurred during both day and night. Live sharks were typically tagged and released unless biological samples were needed.\nStructure of the Data: excel file\nFormating desicions in the data: Station Date is formatted : YYYY,MM,DD HH:MM:SS Species name is listed as its scientific name\nData Validation / Quality Control: This is from a government site so it will hopefully be of good quality\nLicense: No specific license is provided\nThese datasets contain tornado information such as latitude, longtitude, magnitude, and category : https://www.ncdc.noaa.gov/stormevents/\n\n######## tornado data\n\n# NOAA / NCEI\nStormEvents_details_ftp_v1_0_d2024_c20250216 &lt;- read_csv(\"Datasets/Tornado_Datasets/StormEvents_details-ftp_v1.0_d2024_c20250216.csv\")\n\nRows: 67036 Columns: 51\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (26): STATE, MONTH_NAME, EVENT_TYPE, CZ_TYPE, CZ_NAME, WFO, BEGIN_DATE_T...\ndbl (25): BEGIN_YEARMONTH, BEGIN_DAY, BEGIN_TIME, END_YEARMONTH, END_DAY, EN...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n(StormEvents_details_ftp_v1_0_d2024_c20250216)\n\n# A tibble: 67,036 × 51\n   BEGIN_YEARMONTH BEGIN_DAY BEGIN_TIME END_YEARMONTH END_DAY END_TIME\n             &lt;dbl&gt;     &lt;dbl&gt;      &lt;dbl&gt;         &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;\n 1          202405        23       1947        202405      23     1947\n 2          202411        16        230        202411      18     1421\n 3          202405        19       1839        202405      19     1902\n 4          202405        23       2155        202405      23     2155\n 5          202411        22        400        202411      22     1100\n 6          202411         1          0        202411       1     1600\n 7          202411         1          0        202411       1     1600\n 8          202411        22        300        202411      22     1000\n 9          202411        22        200        202411      22     1000\n10          202411        17       1100        202411      18     2100\n# ℹ 67,026 more rows\n# ℹ 45 more variables: EPISODE_ID &lt;dbl&gt;, EVENT_ID &lt;dbl&gt;, STATE &lt;chr&gt;,\n#   STATE_FIPS &lt;dbl&gt;, YEAR &lt;dbl&gt;, MONTH_NAME &lt;chr&gt;, EVENT_TYPE &lt;chr&gt;,\n#   CZ_TYPE &lt;chr&gt;, CZ_FIPS &lt;dbl&gt;, CZ_NAME &lt;chr&gt;, WFO &lt;chr&gt;,\n#   BEGIN_DATE_TIME &lt;chr&gt;, CZ_TIMEZONE &lt;chr&gt;, END_DATE_TIME &lt;chr&gt;,\n#   INJURIES_DIRECT &lt;dbl&gt;, INJURIES_INDIRECT &lt;dbl&gt;, DEATHS_DIRECT &lt;dbl&gt;,\n#   DEATHS_INDIRECT &lt;dbl&gt;, DAMAGE_PROPERTY &lt;chr&gt;, DAMAGE_CROPS &lt;chr&gt;, …\n\nStormEvents_details_ftp_v1_0_d2023_c20250216 &lt;- read_csv(\"Datasets/Tornado_Datasets/StormEvents_details-ftp_v1.0_d2023_c20250216.csv\")\n\nWarning: One or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\n\n\nRows: 75596 Columns: 51\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (26): STATE, MONTH_NAME, EVENT_TYPE, CZ_TYPE, CZ_NAME, WFO, BEGIN_DATE_T...\ndbl (24): BEGIN_YEARMONTH, BEGIN_DAY, BEGIN_TIME, END_YEARMONTH, END_DAY, EN...\nlgl  (1): CATEGORY\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nStormEvents_details_ftp_v1_0_d2022_c20241121 &lt;- read_csv(\"Datasets/Tornado_Datasets/StormEvents_details-ftp_v1.0_d2022_c20241121.csv\")\n\nRows: 69886 Columns: 51\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (26): STATE, MONTH_NAME, EVENT_TYPE, CZ_TYPE, CZ_NAME, WFO, BEGIN_DATE_T...\ndbl (25): BEGIN_YEARMONTH, BEGIN_DAY, BEGIN_TIME, END_YEARMONTH, END_DAY, EN...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nStormEvents_details_ftp_v1_0_d2021_c20240716 &lt;- read_csv(\"Datasets/Tornado_Datasets/StormEvents_details-ftp_v1.0_d2021_c20240716.csv\")\n\nWarning: One or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\n\n\nRows: 61389 Columns: 51\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (26): STATE, MONTH_NAME, EVENT_TYPE, CZ_TYPE, CZ_NAME, WFO, BEGIN_DATE_T...\ndbl (24): BEGIN_YEARMONTH, BEGIN_DAY, BEGIN_TIME, END_YEARMONTH, END_DAY, EN...\nlgl  (1): CATEGORY\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nStormEvents_details_ftp_v1_0_d2020_c20240620 &lt;- read_csv(\"Datasets/Tornado_Datasets/StormEvents_details-ftp_v1.0_d2020_c20240620.csv\")\n\nRows: 61279 Columns: 51\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (26): STATE, MONTH_NAME, EVENT_TYPE, CZ_TYPE, CZ_NAME, WFO, BEGIN_DATE_T...\ndbl (25): BEGIN_YEARMONTH, BEGIN_DAY, BEGIN_TIME, END_YEARMONTH, END_DAY, EN...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nWho collected the Data: The data was collected by the NCEI which is a port of NOAA\nWhy was the data collected: To document tornadoes that cause harm, property damage, or economic disruption\nWhat the data is about: The description, location, and magnitude of tornadoes in the United States\nWhen the data was collected: The datasets listed here are from 1950, and from 2020-2024. The NCEI has been documenting tornadoes since 1950. Each year is contained in its own dataframe before any data cleaning is done\nWhere the data was collected: The United Sates\nHow was the data generated: The National Weather Service is the main source of tornado data, which they collect through their network of weather forecast offices\nStructure of the Data: .csv file\nFormating desicions in the data: Dates are listed as YEARMONTH: YYYYMM, and Days are listed as Start Day and End Day\nData Validation / Quality Control: This is from a government site so it will hopefully be of good quality There are some missing values in the data\nLicense: No specific license is provided\nHere is the dataset I chose to plot coastal data: https://pubs.usgs.gov/of/2013/1284/title_page.html\n\n# coastal data\nlibrary(sf)\n\nLinking to GEOS 3.13.0, GDAL 3.10.1, PROJ 9.5.1; sf_use_s2() is TRUE\n\nCZMP_counties_2009 &lt;- \n  read_sf(\"Datasets/Coastal Datasets/CZMP_counties_2009/CZMP_counties_2009.shp\")\n\nWho collected the Data: The data was collected by the United States Geological Survey\nWhy was the data collected: The data was collected to create a shapefile of 492 Coastal Zone Management Program (CZMP) counties in the United States and some territories\nWhat the data is about: Coastline data from the United States\nWhen the data was collected: The data is from coastal ground conditions in 2009\nWhere the data was collected: The United Sates\nHow was the data generated: The CZMP counties shapefile was created using a three-step process involving the 2008 TIGER/Line shapefile, a NOAA list of CZMP counties, and reconciliation with historical county changes. In 2009, updates were made to align with the latest TIGER/Line data, increasing the dataset to 492 counties and 501 polygons. The shapefile was further revised following Alaska’s withdrawal from the CZMP in 2011, but Alaskan county equivalents were retained for geographic reference, with a note that the data reflects 2009 conditions.\nStructure of the Data: .shp file There is also a lot of other files that are contained in the Coastal Datasets folder in the Datasets folder\nFormating desicions in the data: The ‘geometry’ column contains shape data on the latitude and longitude of the coasts that will need to be properly formatted when plotting\nData Validation / Quality Control: This is from a government site so it will hopefully be of good quality\nLicense: No specific license is provided From the USGS: “The USGS is committed to and is making every possible effort to ensure that all electronic and information technology developed, procured, maintained, or used by the USGS is accessible to people with disabilities, including both our employees and the customers we serve.”\nSuggested Data Analysis Methods :\nUse the Latitude and Longitude columns to plot the location of each shark When the shapefile for the coastal areas are plotted, we can see where these sharks are compared to the coastal areas Next, plot the torando start points and end points are plotted and find a way to code each tornado to a color or shape to help identify their category strength or magnitude\nFinally, we can see if there is a high density of tornadoes that form close to the coast and also near shark infested waters that move inwards towards cities",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Draft: Data Documentation</span>"
    ]
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "1  Introduction",
    "section": "",
    "text": "This is a book created from markdown and executable code.\nSee Knuth (1984) for additional discussion of literate programming.\n\n\n\n\nKnuth, Donald E. 1984. “Literate Programming.” Comput. J. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "summary.html",
    "href": "summary.html",
    "title": "2  Summary",
    "section": "",
    "text": "In summary, this book has no content whatsoever.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Summary</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Knuth, Donald E. 1984. “Literate Programming.” Comput.\nJ. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97.",
    "crumbs": [
      "References"
    ]
  }
]